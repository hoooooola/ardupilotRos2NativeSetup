# ğŸ¤– ArduPilot ROS 2 è¦–è¦ºç³»çµ±

## ğŸ“‹ ç³»çµ±æ¶æ§‹

```
Gazebo ç›¸æ©Ÿ
    â†“
ROS 2 Bridge (/camera/image_raw)
    â†“
å½¢ç‹€åµæ¸¬å™¨ (shape_detector.py)
    â†“
æ¨™è¨»å½±åƒ (/camera/annotated) + åµæ¸¬çµæœ (/detections)
    â†“
H.264 ä¸²æµå™¨ â†’ QGroundControl (UDP:5600)
```

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. è‡ªå‹•å•Ÿå‹• (æ¨è–¦)
```bash
./native_sim_launch.sh
```

é€™æœƒè‡ªå‹•å•Ÿå‹•:
- âœ… ArduPilot SITL
- âœ… Gazebo Fortress
- âœ… ROS 2 Bridge
- âœ… å½¢ç‹€åµæ¸¬å™¨
- âœ… H.264 è¦–è¨Šä¸²æµåˆ° QGC

### 2. æ‰‹å‹•æ¸¬è©¦å€‹åˆ¥çµ„ä»¶

#### æ¸¬è©¦å½¢ç‹€åµæ¸¬å™¨:
```bash
source /opt/ros/humble/setup.bash
python3 ros2_scripts/shape_detector.py
```

#### ç›£æ§åµæ¸¬çµæœ:
```bash
source /opt/ros/humble/setup.bash
python3 ros2_scripts/detection_monitor.py
```

#### æ¸¬è©¦ H.264 ä¸²æµ:
```bash
source /opt/ros/humble/setup.bash
python3 ros2_scripts/annotated_streamer_h264.py
```

## ğŸ¯ ç›®å‰åŠŸèƒ½

### å½¢ç‹€åµæ¸¬ (OpenCV)
- âœ… ä¸‰è§’å½¢ (Triangle)
- âœ… æ­£æ–¹å½¢ (Square)
- âœ… çŸ©å½¢ (Rectangle)
- âœ… äº”é‚Šå½¢ (Pentagon)
- âœ… å…­é‚Šå½¢ (Hexagon)
- âœ… åœ“å½¢ (Circle)

### è¼¸å‡ºè³‡è¨Š
- å½¢ç‹€é¡å‹
- é¢ç©å¤§å°
- ä¸­å¿ƒåº§æ¨™
- é ‚é»æ•¸é‡

## ğŸ§  å‡ç´šåˆ°æ·±åº¦å­¸ç¿’ (YOLO/TensorFlow)

### æ–¹æ¡ˆ 1: YOLO (æ¨è–¦ç”¨æ–¼å³æ™‚ç‰©é«”åµæ¸¬)

#### å®‰è£ YOLOv8:
```bash
pip3 install ultralytics
```

#### ä¿®æ”¹ `shape_detector.py`:
```python
from ultralytics import YOLO

class YOLODetector(Node):
    def __init__(self):
        super().__init__('yolo_detector')
        # è¼‰å…¥é è¨“ç·´æ¨¡å‹
        self.model = YOLO('yolov8n.pt')  # nano ç‰ˆæœ¬,é€Ÿåº¦å¿«
        
    def detect_objects(self, image):
        results = self.model(image, conf=0.5)
        detections = []
        
        for r in results:
            for box in r.boxes:
                cls = int(box.cls[0])
                conf = float(box.conf[0])
                x1, y1, x2, y2 = box.xyxy[0].tolist()
                
                detections.append({
                    "class": self.model.names[cls],
                    "confidence": conf,
                    "bbox": [x1, y1, x2, y2]
                })
        
        return detections
```

### æ–¹æ¡ˆ 2: TensorFlow Object Detection

#### å®‰è£:
```bash
pip3 install tensorflow opencv-python
```

#### ä½¿ç”¨é è¨“ç·´æ¨¡å‹:
```python
import tensorflow as tf

# è¼‰å…¥ SSD MobileNet
model = tf.saved_model.load('ssd_mobilenet_v2/saved_model')
```

### æ–¹æ¡ˆ 3: Jetson Inference (å¦‚æœåœ¨ Jetson ä¸Šé‹è¡Œ)

æ‚¨æåˆ°çš„ Isaac/Jetpack inference è…³æœ¬å¯ä»¥é€™æ¨£æ•´åˆ:

```python
import jetson.inference
import jetson.utils

class JetsonDetector(Node):
    def __init__(self):
        super().__init__('jetson_detector')
        # ä½¿ç”¨ Jetson ç¡¬é«”åŠ é€Ÿ
        self.net = jetson.inference.detectNet("ssd-mobilenet-v2", threshold=0.5)
        
    def detect_objects(self, cv_image):
        # è½‰æ›ç‚º CUDA æ ¼å¼
        cuda_img = jetson.utils.cudaFromNumpy(cv_image)
        
        # åŸ·è¡Œåµæ¸¬
        detections = self.net.Detect(cuda_img)
        
        results = []
        for detection in detections:
            results.append({
                "class": self.net.GetClassDesc(detection.ClassID),
                "confidence": detection.Confidence,
                "bbox": [detection.Left, detection.Top, 
                        detection.Right, detection.Bottom]
            })
        
        return results
```

## ğŸ“Š ROS 2 ä¸»é¡Œ

### è¨‚é–±:
- `/camera/image_raw` - åŸå§‹ç›¸æ©Ÿå½±åƒ

### ç™¼å¸ƒ:
- `/camera/annotated` - æ¨™è¨»å¾Œçš„å½±åƒ
- `/detections` - JSON æ ¼å¼çš„åµæ¸¬çµæœ

### æŸ¥çœ‹ä¸»é¡Œ:
```bash
# åˆ—å‡ºæ‰€æœ‰ä¸»é¡Œ
ros2 topic list

# æŸ¥çœ‹åµæ¸¬çµæœ
ros2 topic echo /detections

# æŸ¥çœ‹å½±åƒé »ç‡
ros2 topic hz /camera/image_raw
```

## ğŸ® æ•´åˆç„¡äººæ©Ÿæ§åˆ¶

### å»ºç«‹æ±ºç­–ç¯€é»:
```python
class VisionController(Node):
    def __init__(self):
        super().__init__('vision_controller')
        
        # è¨‚é–±åµæ¸¬çµæœ
        self.create_subscription(String, '/detections', self.on_detection, 10)
        
        # ç™¼å¸ƒæ§åˆ¶æŒ‡ä»¤
        self.cmd_pub = self.create_publisher(...)
        
    def on_detection(self, msg):
        data = json.loads(msg.data)
        
        # æ ¹æ“šåµæ¸¬çµæœåšæ±ºç­–
        if "person" in [d["class"] for d in data["detections"]]:
            self.get_logger().warn("Person detected! Taking action...")
            # ç™¼é€æ§åˆ¶æŒ‡ä»¤
```

## ğŸ”§ æ•ˆèƒ½èª¿æ•´

### é™ä½å»¶é²:
- èª¿æ•´ H.264 bitrate (ç›®å‰ 2000 kbps)
- ä½¿ç”¨ `speed-preset=ultrafast`
- å•Ÿç”¨ `Low Latency Mode` in QGC

### æé«˜æº–ç¢ºåº¦:
- å¢åŠ å½±åƒè§£æåº¦ (éœ€ä¿®æ”¹ Gazebo SDF)
- èª¿æ•´åµæ¸¬é–¾å€¼
- ä½¿ç”¨æ›´å¤§çš„ YOLO æ¨¡å‹ (yolov8m, yolov8l)

### GPU åŠ é€Ÿ:
```bash
# æª¢æŸ¥ CUDA å¯ç”¨æ€§
python3 -c "import torch; print(torch.cuda.is_available())"

# ä½¿ç”¨ GPU ç‰ˆæœ¬çš„ PyTorch
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

## ğŸ“ ä¸‹ä¸€æ­¥é–‹ç™¼

1. **ç‰©é«”è¿½è¹¤**: åŠ å…¥ DeepSORT æˆ– ByteTrack
2. **èªç¾©åˆ†å‰²**: ä½¿ç”¨ Mask R-CNN æˆ– YOLACT
3. **3D åµæ¸¬**: æ•´åˆæ·±åº¦ç›¸æ©Ÿ
4. **è‡ªä¸»å°èˆª**: æ ¹æ“šè¦–è¦ºè¼¸å…¥è¦åŠƒè·¯å¾‘

## ğŸ› é™¤éŒ¯

### æŸ¥çœ‹æ—¥èªŒ:
```bash
# åœ¨ tmux ä¸­åˆ‡æ›çª—æ ¼
Ctrl+b, ç„¶å¾ŒæŒ‰æ–¹å‘éµ

# æŸ¥çœ‹ ROS 2 æ—¥èªŒ
ros2 node list
ros2 node info /shape_detector
```

### è¦–è¦ºåŒ–:
```bash
# ä½¿ç”¨ rqt_image_view æŸ¥çœ‹å½±åƒ
rqt_image_view
```

## ğŸ“š åƒè€ƒè³‡æº

- [YOLOv8 æ–‡æª”](https://docs.ultralytics.com/)
- [TensorFlow Object Detection](https://github.com/tensorflow/models/tree/master/research/object_detection)
- [Jetson Inference](https://github.com/dusty-nv/jetson-inference)
- [ROS 2 Vision](https://github.com/ros-perception)
